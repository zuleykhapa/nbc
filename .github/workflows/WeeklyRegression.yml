name: Weekly Regression
on:
  schedule:
    - cron:  '0 1 * * MON' # runs at 2am CET MONDAY
  workflow_dispatch:

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}-${{ github.head_ref || '' }}-${{ github.base_ref || '' }}-${{ github.ref != 'refs/heads/main' || github.sha }}
  cancel-in-progress: true

env:
  GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
  gh_issue_repo: zuleykhapa/nbc
  mounted_directory_name: mount-point

jobs:
  define-matrix:
    name: Check if there are recent commits to feature and define matrix
    runs-on: ubuntu-latest
    outputs:
      branches: ${{ steps.branches.outputs.branches }}

    steps:
      - name: checkout DuckDB
        id: checkout
        continue-on-error: true
        uses: actions/checkout@v4
        with:
          repository: duckdb/duckdb
          fetch-depth: 0
      - name: define matrix
        id: branches
        run: |
          count=$(git log origin/feature --since="7 days ago" | wc -l)
          if [[ "${{ steps.checkout.outcome }}" == "failure" ]] || [[ $count -eq 0 ]]; then
            echo 'branches=["main"]' >> $GITHUB_OUTPUT
          else
            echo 'branches=["main", "feature"]' >> $GITHUB_OUTPUT
          fi
    
  check-nightly-builds:
    name: Check Nightly Build failures
    if: always()
    needs:
      - define-matrix
    runs-on: ubuntu-latest
    steps:
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Checkout a repo with the "count_consecutive_failures" script
        uses: actions/checkout@v4
        with:
          repository: ${{ env.gh_issue_repo }}
          sparse-checkout: |
            scripts/
            requirements.txt
          path: ${{ env.mounted_directory_name }}

      - name: Install requirements
        shell: bash
        working-directory: ${{ env.mounted_directory_name }}
        run: | 
          python -m venv .venv
          .venv/bin/python -m pip install -r requirements.txt
          source .venv/bin/activate
      - name: Create run status report for nightly-builds on 'main'
        working-directory: ${{ env.mounted_directory_name }}
        continue-on-error: true
        run: |
          # count consecutive failures and create a nightly_builds_status.md file
          python -X faulthandler -m trace --trace scripts/count_consecutive_failures_WR.py
      - name: Upload nightly-build status
        uses: actions/upload-artifact@v4
        if: success()
        with:
          name: nightly_builds_status
          path: ${{ env.mounted_directory_name }}/nightly_builds_status.md
          if-no-files-found: error

  start-runner:
    name: Start self-hosted ec2 runner
    needs: 
      - define-matrix
    runs-on: ubuntu-latest
    env:
      instance_id: i-0a6cd2153bfd28349

    
    steps:
      - name: Start EC2 runner
        shell: bash
        env:
          AWS_ACCESS_KEY_ID: ${{secrets.AWS_ACCESS_KEY_ID}}
          AWS_SECRET_ACCESS_KEY: ${{secrets.AWS_SECRET_ACCESS_KEY}}
          AWS_DEFAULT_REGION: us-east-1
        run: aws ec2 start-instances --instance-id ${{ env.instance_id }}

      - name: Create issue if failure
        shell: bash
        if: ${{ failure() && contains(github.ref_name, 'main') }}
        run: |
          gh issue create --repo ${{ env.gh_issue_repo }} --title "Weekly Regression Test Failure" --body "AWS box with instance-id ${{ env.instance_id }} could not be started"
  
  configure-mount-and-download-benchmark-data:
    name: Configure mount and download benchmark data
    needs: 
      - define-matrix
      - start-runner
    runs-on: self-hosted
    env:
      AWS_PROFILE: user1

    steps:
      - name: Install
        shell: bash
        run: |
          sudo apt-get update -y -qq && sudo apt-get install -y -qq g++ ninja-build cmake make python-is-python3 libssl-dev pip jq python3-requests 
      - name: umount mount-point (helps with debugging)
        shell: bash
        run: |
          if [ ! -d ${{ env.mounted_directory_name }} ] ; then 
            mkdir ${{ env.mounted_directory_name }}
            exit 0;
          fi 
          if mountpoint -q ${{ env.mounted_directory_name }} ; then
            # unmount mount-point. During debugging the mount can cause steps
            # to fail when copying duckdb-main to duckdb-old
            rm -rf ${{ env.mounted_directory_name }}/*
            sudo umount ${{ env.mounted_directory_name }}
          fi
      - name: Mount to instance storage
        shell: bash
        run: |
          # sometimes the mount point changes, by parsing the output of lsblk
          # we can always get the right mount point
          mount_name=$(sudo lsblk | awk 'NR > 1{
            size = $4;
            gsub(/MB/, "", size);
            gsub(/KB/, "", size);
            if (size ~ /M/) size /= 1024;       # Already in MB
            else if (size ~ /K/) size /= (1024*1024); # Convert KB to GB
            if (size > 800) print $1;
          }' | head -1)
          rm -rf ${{ env.mounted_directory_name }}
          sudo mkfs -t xfs -f /dev/$mount_name
          mkdir ${{ env.mounted_directory_name }}
          sudo mount /dev/$mount_name ${{ env.mounted_directory_name }}
          sudo chown -R ubuntu ${{ env.mounted_directory_name }}
      - name: Load data for sf100 benchmarks.
        shell: bash
        working-directory: ${{ env.mounted_directory_name}}
        run: |
          wget https://duckdb-blobs.s3.us-east-1.amazonaws.com/data/tpch-sf100.db -O tpch_sf100.duckdb
          # wget https://duckdb-blobs.s3.us-east-1.amazonaws.com/data/tpcds_sf100.db -O tpcds_sf100.duckdb
          # aws s3 ccp s3://duckdb-blobs/data/tpch-sf100.db tpch_sf100.duckdb
          # aws s3 cp s3://duckdb-blobs/data/tpcds_sf100.db tpcds_sf100.duckdb
  
  build-and-setup:
    name: Build DuckDB versions and link the benchmarks
    needs: 
      - define-matrix
      - configure-mount-and-download-benchmark-data
    strategy:
      matrix:
        branch: ${{ fromJSON(needs.define-matrix.outputs.branches) }}
      fail-fast: false
    runs-on: self-hosted
    env:
      GEN: ninja
      BUILD_BENCHMARK: 1
      BUILD_TPCH: 1
      BUILD_TPCDS: 1
      BUILD_JSON: 1
      BUILD_HTTPFS: 1
      BUILD_ICU: 1
      BUILD_JEMALLOC: 1
      CORE_EXTENSIONS: "inet"
      regression_output: regression_output.txt
    outputs:
      failed_build: ${{ steps.failed-build.outputs.failed_build }}
    steps:
      - name: checkout duckdb-curr
        uses: actions/checkout@v4
        with:
          repository: 'duckdb/duckdb'
          ref: ${{ matrix.branch }}
          fetch-depth: 0
          path: ${{ env.mounted_directory_name}}/duckdb-curr-${{ matrix.branch }}

      - name: checkout duckdb-old
        uses: actions/checkout@v4
        with:
          repository: 'duckdb/duckdb'
          ref: ${{ matrix.branch }}
          fetch-depth: 0
          path: ${{ env.mounted_directory_name}}/duckdb-old-${{ matrix.branch }}

      - name: Checkout duckdb-old to week ago version
        shell: bash
        working-directory: ${{ env.mounted_directory_name }}/duckdb-old-${{ matrix.branch }}
        run: |
          git checkout $( cat ../../duckdb_curr_version_${{ matrix.branch }}.txt )
      - name: Store current git hash of duckdb-curr
        shell: bash
        working-directory: ${{ env.mounted_directory_name }}/duckdb-curr-${{ matrix.branch }}
        run: |
          # update duckdb_curr_version_${{ matrix.branch }}.txt
          git rev-parse --verify HEAD > ../../duckdb_curr_version_${{ matrix.branch }}.txt
      - name: Build old and current
        shell: bash
        working-directory: ${{ env.mounted_directory_name }}
        run: |
          cd duckdb-curr-${{ matrix.branch }} && make clean && make
          cd ..
          cd duckdb-old-${{ matrix.branch }} && make clean && make
      - name: Set up benchmarks 
        shell: bash
        working-directory: ${{ env.mounted_directory_name }}/duckdb-old-${{ matrix.branch }}
        run: |
          # we do this so new added benchmarks that break duckdb old
          # do not cause failures.
          rm -rf ../duckdb-curr-${{ matrix.branch }}/benchmark
          mkdir ../duckdb-curr-${{ matrix.branch }}/benchmark
          cp -r benchmark ../duckdb-curr-${{ matrix.branch }}
      # - name: Link duckdb-curr/duckdb_benchmark_data to tpch_sf100.duckdb and tpcds_sf100.duckdb
      #   shell: bash 
      #   working-directory: ${{ env.mounted_directory_name }}/duckdb-curr-${{ matrix.branch }}
      #   run: |
      #     mkdir duckdb_benchmark_data
      #     cd duckdb_benchmark_data
      #     ln -s ${{ github.workspace }}/${{ env.mounted_directory_name }}/tpch_sf100.duckdb .
          # ln -s ${{ github.workspace }}/${{ env.mounted_directory_name }}/tpcds_sf100.duckdb .
    
      # - name: Link duckdb-old/duckdb_benchmark_data to tpch_sf100.duckdb and tpcds_sf100.duckdb
      #   shell: bash 
      #   working-directory: ${{ env.mounted_directory_name }}/duckdb-old-${{ matrix.branch }}
      #   run: |
      #     mkdir duckdb_benchmark_data
      #     cd duckdb_benchmark_data
      #     ln -s ${{ github.workspace }}/${{ env.mounted_directory_name }}/tpch_sf100.duckdb .
          # ln -s ${{ github.workspace }}/${{ env.mounted_directory_name }}/tpcds_sf100.duckdb .
      
      # - name: Generate micro_extended.csv and copy to duckdb-curr-${{ matrix.branch }}
      #   shell: bash
      #   working-directory: ${{ env.mounted_directory_name }}/duckdb-old-${{ matrix.branch }}
      #   run: |
      #     find benchmark/micro | grep ".*.benchmark" | sort > .github/regression/micro_extended.csv
      #     cp .github/regression/micro_extended.csv ../duckdb-curr-${{ matrix.branch }}/.github/regression/micro_extended.csv

      - id: failed-build
        shell: bash
        if: failure()
        run: |
          echo "failed_build=${{ matrix.branch }}" >> $GITHUB_OUTPUT
  run-regression-tests:
    name: Run Regression Tests
    if: always()
    needs: 
      - define-matrix
      - configure-mount-and-download-benchmark-data
      - build-and-setup
    runs-on: self-hosted
    strategy:
      fail-fast: false
      matrix:
        branch: ${{ fromJSON(needs.define-matrix.outputs.branches) }}
        test: ['large/tpch.csv']
        # test: ['large/tpch.csv', 'large/ingestion.csv', 'micro_extended.csv', 'large/tpcds.csv']
        exclude: 
          - branch: ${{ needs.build-and-setup.outputs.failed_build }}
    outputs:
      file_name: ${{ steps.create.outputs.file_name }}
        
    steps:
      - name: Create a File Name 
        if: always()
        id: create
        shell: bash
        working-directory: ${{ env.mounted_directory_name }}
        run: |
          echo "file_name=$(echo regression_output_${{ matrix.test }}_${{ matrix.branch }}.txt | sed -e 's/\//_/g' -e 's/\.csv//')" >> $GITHUB_OUTPUT
      - name: checkout
        uses: actions/checkout@v4
        with:
          repository: ${{github.repository}}
          ref: 'main'
          sparse-checkout: regression_output_micro_extended_main.txt
          path: ${{ env.mounted_directory_name }}/reg
      - name: Run Regression Test
        if: contains(${{ steps.create.outputs.file_name }}, 'regression')
        continue-on-error: true
        shell: bash
        working-directory: ${{ env.mounted_directory_name }}
        run: |
          # export disable_timeout=""
          # if [[ ${{ matrix.test }} == large/tpcds.csv ]]; then
          #   disable_timeout="--disable-timeout"
          # fi
          # python duckdb-curr-${{ matrix.branch }}/scripts/regression/test_runner.py \
          #   --old=duckdb-old-${{ matrix.branch }}/build/release/benchmark/benchmark_runner \
          #   --new=duckdb-curr-${{ matrix.branch }}/build/release/benchmark/benchmark_runner \
          #   --benchmarks=duckdb-curr-${{ matrix.branch }}/.github/regression/${{ matrix.test }} $disable_timeout \
          #   --verbose > ${{ steps.create.outputs.file_name }}
          
          cat reg/*.txt >> ${{ steps.create.outputs.file_name }}
          
      - name: Upload results
        uses: actions/upload-artifact@v4
        if: success()
        with:
          name: ${{ steps.create.outputs.file_name }}
          path: ${{ env.mounted_directory_name }}/${{ steps.create.outputs.file_name }}
          if-no-files-found: error

  collect-issues:
    name: Collect issues
    needs: 
      - start-runner
      - define-matrix
      - configure-mount-and-download-benchmark-data
      - build-and-setup
      - check-nightly-builds
      - run-regression-tests
    if: always()
    runs-on: self-hosted
    defaults:
      run:
        shell: bash
        working-directory: ${{ env.mounted_directory_name }}
    strategy:
      matrix: 
        branch: ${{ fromJSON(needs.define-matrix.outputs.branches) }}
        exclude: 
          - branch: ${{ needs.build-and-setup.outputs.failed_build }}

    steps:
      - name: Download Benchmarks issues
        uses: actions/download-artifact@v4
        with:
          pattern: regression_output_*.txt 
          path: ${{ env.mounted_directory_name }}/regression_output

      - name: Collect Benchmarks issues
        # if: contains(github.ref_name, 'main')
        run: |
          # get versions
          ./duckdb-old-${{ matrix.branch }}/build/release/duckdb -c "pragma version" > ${{ matrix.branch }}_old_version.txt
          ./duckdb-curr-${{ matrix.branch }}/build/release/duckdb -c "pragma version" > ${{ matrix.branch }}_curr_version.txt
          printf "\`\`\` \nRegressed Version of Branch: ${{ matrix.branch }} \n$(cat ${{ matrix.branch }}_curr_version.txt)\n\
          OLD VERSION of Branch: ${{ matrix.branch }}\n$(cat ${{ matrix.branch }}_old_version.txt) \n \`\`\` \n" >> issue_body_${{ matrix.branch }}.txt
          # collect issues on benchmarks runs
          # for output in regression_output/regression_output*/regression*.txt; do
          for output in $(ls regression_output); do
            if ! grep -q "NO REGRESSIONS DETECTED" "$output"; then
              printf "[ ${{ matrix.branch }} ] [ Regression Test $output ]\n" >> issue_body_${{ matrix.branch }}.txt
              printf "Regression Output \n \`\`\` \n $(awk '/REGRESSIONS DETECTED/,/OTHER TIMINGS/' $output) \n \`\`\` \n"  >> issue_body_${{ matrix.branch }}.txt
            fi
          done
          ls regression_output
          cat issue_body_${{ matrix.branch }}.txt
          
  file-issue:
    name: File Issue
    needs: 
      - start-runner
      - define-matrix
      - configure-mount-and-download-benchmark-data
      - build-and-setup
      - check-nightly-builds
      - run-regression-tests
      - collect-issues
    if: always()
    runs-on: self-hosted
    defaults:
      run:
        shell: bash
        working-directory: ${{ env.mounted_directory_name }}
    steps:
      - name: Download nightly build status
        uses: actions/download-artifact@v4
        with:
          name: nightly_builds_status 
          path: ${{ env.mounted_directory_name }}

      # - name: File issue on preparation steps
      #   if: |
      #       contains(github.ref_name, 'main') && 
      #       (needs.configure-mount-and-download-benchmark-data.result != 'success' ||
      #       needs.build-and-setup.result != 'success')
      #   run: |
      #     echo -e "Benchmark preparation steps have failed, please check the \
      #       [workflow run](https://github.com/duckdblabs/duckdb-internal/actions/runs/${{ github.run_id }}) for details.\n\n" > report.txt

      - name: Create Regressions Report
        run: |
          if grep -q "REGRESSIONS DETECTED" issue_body*.txt; then
            echo "Regressions detected, GitHub issue will be filed."
            cat issue_body*.txt >> report.txt
          fi
      - name: Add Nightly-Build Failures to Report
        run: |
          if grep -q "nightly-build" nightly_builds_status.md; then
            echo "Adding nightly-build report to GitHub issue."
            cat nightly_builds_status.md >> report.txt
          fi
          cat report.txt
      - uses: actions/upload-artifact@v4
        with:
          name: REPORT
          path: ${{ env.mounted_directory_name }}/report.txt
      # - name: Create Issue
      #   if: success()
      #   run: |
      #     if [ -f report.txt ]; then
      #       # create issue
      #       gh issue create --repo zuleykhapa/nbc.github.io --title "Weekly Regression Test Failure" --body-file report.txt
      #     fi

  shutdown:
    name: shut down
    if: always()
    runs-on: self-hosted
    needs:
      - start-runner
      - check-nightly-builds
      - file-issue

    steps:
      - name: shutdown
        shell: bash
        run: sudo shutdown