name: Weekly Regression
on:
  # schedule:
  #   - cron:  '0 1 * * MON' # runs at 2am CET MONDAY
  workflow_dispatch:

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}-${{ github.head_ref || '' }}-${{ github.base_ref || '' }}-${{ github.ref != 'refs/heads/main' || github.sha }}
  cancel-in-progress: true

env:
  GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
  gh_issue_repo: duckdblabs/duckdb-internal
  mounted_directory_name: mount-point
  REGESSION_THRESHOLD_SECONDS: 1.0

jobs:
  start-runner:
    name: Start self-hosted ec2 runner
    runs-on: ubuntu-latest
    env:
      instance_id: i-0a6cd2153bfd28349

    steps:
      - name: Start EC2 runner
        shell: bash
        env:
          AWS_ACCESS_KEY_ID: ${{secrets.AWS_ACCESS_KEY_ID}}
          AWS_SECRET_ACCESS_KEY: ${{secrets.AWS_SECRET_ACCESS_KEY}}
          AWS_DEFAULT_REGION: us-east-1
        run: aws ec2 start-instances --instance-id ${{ env.instance_id }}

      - name: Create issue if failure
        shell: bash
        if: ${{ failure() && contains(github.ref_name, 'main') }}
        run: |
          gh issue create --repo ${{ env.gh_issue_repo }} --title "Weekly Regression Test Failure" --body "AWS box with instance-id ${{ env.instance_id }} could not be started"

  configure-mount-and-download-benchmark-data:
    name: Configure mount and download benchmark data
    needs: 
      - start-runner
    runs-on: self-hosted
    env:
      AWS_PROFILE: user1

    steps:
      - name: Install
        shell: bash
        run: sudo apt-get update -y -qq && sudo apt-get install -y -qq g++ ninja-build cmake make python-is-python3 libssl-dev pip gh jq python3-requests libcurl4-openssl-dev

      - name: umount mount-point (helps with debugging)
        shell: bash
        run: |
          if [ ! -d ${{ env.mounted_directory_name }} ] ; then 
            mkdir ${{ env.mounted_directory_name }}
            exit 0;
          fi 
          if mountpoint -q ${{ env.mounted_directory_name }} ; then
            # unmount mount-point. During debugging the mount can cause steps
            # to fail when copying duckdb-main to duckdb-old
            rm -rf ${{ env.mounted_directory_name }}/*
            sudo umount ${{ env.mounted_directory_name }}
          fi

      - name: Mount to instance storage
        shell: bash
        run: |
          # sometimes the mount point changes, by parsing the output of lsblk
          # we can always get the right mount point
          mount_name=$(sudo lsblk | awk 'NR > 1{
            size = $4;
            gsub(/MB/, "", size);
            gsub(/KB/, "", size);

            if (size ~ /M/) size /= 1024;       # Already in MB
            else if (size ~ /K/) size /= (1024*1024); # Convert KB to GB

            if (size > 800) print $1;
          }' | head -1)
          rm -rf ${{ env.mounted_directory_name }}
          sudo mkfs -t xfs -f /dev/$mount_name
          mkdir ${{ env.mounted_directory_name }}
          sudo mount /dev/$mount_name ${{ env.mounted_directory_name }}
          sudo chown -R ubuntu ${{ env.mounted_directory_name }}

      - name: Load data for sf100 benchmarks.
        shell: bash
        working-directory: ${{ env.mounted_directory_name}}
        run: |
          # wget https://blobs.duckdb.org/data/tpch-sf100.db -O tpch_sf100.duckdb
          # wget http://blobs.duckdb.org/data/tpcds_sf100.db -O tpcds_sf100.duckdb
          # aws s3 cp s3://duckdb-blobs/data/tpch-sf100.db tpch_sf100.duckdb
          # aws s3 cp s3://duckdb-blobs/data/tpcds_sf100.db tpcds_sf100.duckdb

  define-matrix:
    name: Define matrix of pairs
    needs: configure-mount-and-download-benchmark-data
    runs-on: self-hosted
    outputs:
      versions: ${{ steps.create-version-pairs.outputs.pairs }}

    steps:
      - name: Sparse-checkout repo with a script
        uses: actions/checkout@v4
        with:
          sparse-checkout: scripts/create_pairs_matrix.py
          path: ${{ env.mounted_directory_name }}/scripts

      - name: checkout duckdb
        uses: actions/checkout@v4
        with:
          repository: 'duckdb/duckdb'
          fetch-depth: 0
          path: ${{ env.mounted_directory_name}}/duckdb
      
      - name: create pairs.json
        working-directory: ${{ env.mounted_directory_name }}
        run: |
          mv scripts/scripts/create_pairs_matrix.py duckdb/scripts
          cd duckdb
          python scripts/create_pairs_matrix.py
        
      - name: move pairs.json
        run: mv ${{ env.mounted_directory_name }}/duckdb_previous_version_pairs.json .
            
      - name: Read JSON and create version pairs matrix
        working-directory: ${{ env.mounted_directory_name }}
        id: create-version-pairs
        run: |
          pairs=$(cat ../duckdb_previous_version_pairs.json | jq -c '.')
          echo "pairs=$pairs" >> $GITHUB_OUTPUT
          
  build-and-setup:
    name: BUILD - ${{ matrix.versions.new_name }} vs ${{ matrix.versions.old_name }}
    needs: 
      - define-matrix
      - configure-mount-and-download-benchmark-data
    strategy:
      matrix:
        versions: ${{ fromJSON(needs.define-matrix.outputs.versions) }}
      fail-fast: false
    runs-on: self-hosted
    env:
      GEN: ninja
      BUILD_BENCHMARK: 1
      BUILD_TPCH: 1
      BUILD_TPCDS: 1
      BUILD_JSON: 1
      BUILD_HTTPFS: 1
      BUILD_ICU: 1
      BUILD_JEMALLOC: 1
      CORE_EXTENSIONS: "inet"
      regression_output: regression_output.txt
    steps:
      - name: checkout duckdb-curr (${{ matrix.versions.new_name }})
        uses: actions/checkout@v4
        with:
          repository: 'duckdb/duckdb'
          ref: ${{ matrix.versions.new_sha }}
          fetch-depth: 0
          path: ${{ env.mounted_directory_name}}/duckdb-curr-${{ matrix.versions.new_name }}

      - name: checkout duckdb-old (${{ matrix.versions.old_name }})
        uses: actions/checkout@v4
        with:
          repository: 'duckdb/duckdb'
          ref: ${{ matrix.versions.old_sha }}
          fetch-depth: 0
          path: ${{ env.mounted_directory_name}}/duckdb-old-${{ matrix.versions.old_name }}

      # - name: Build new (${{ matrix.versions.new_name }}) and old (${{ matrix.versions.old_name }})
      #   shell: bash
      #   working-directory: ${{ env.mounted_directory_name }}
      #   run: |
      #     cd duckdb-curr-${{ matrix.versions.new_name }} && make clean && make
      #     cd ..
      #     cd duckdb-old-${{ matrix.versions.old_name }} && make clean && make

      - name: generate micro_extended.csv in duckdb-old-${{ matrix.versions.old_name }}
        shell: bash
        working-directory: ${{ env.mounted_directory_name }}
        run: |
          old_dir_name="duckdb-old-${{ matrix.versions.old_name }}"
          new_dir_name="duckdb-curr-${{ matrix.versions.new_name }}"
          cd ${old_dir_name}/benchmark
          find micro | grep ".*.benchmark" | sort > old_micro_extended.csv
          cat old_micro_extended.csv
          cd ../../${new_dir_name}/benchmark
          find micro | grep ".*.benchmark" | sort > new_micro_extended.csv
          cat new_micro_extended.csv
          cd ../..
          grep -Fxf ${old_dir_name}/benchmark/micro/old_micro_extended.csv ${new_dir_name}/benchmark/micro/new_micro_extended.csv > ${old_dir_name}/.github/regression/micro_extended.csv
          cat .github/regression/micro_extended.csv
          
  #     - name: copy micro_extended to duckdb-curr-${{ matrix.versions.new_name }}
  #       shell: bash
  #       working-directory: ${{ env.mounted_directory_name }}
  #       run: |
  #         cp duckdb-old-${{ matrix.versions.old_name }}/.github/regression/micro_extended.csv duckdb-curr-${{ matrix.versions.new_name }}/.github/regression/
          
  #         ls -lah duckdb-curr-${{ matrix.versions.new_name }}/.github/regression/
  #         ls -lah duckdb-curr-${{ matrix.versions.new_name }}/.github/regression/large
          
  #     - name: Set up benchmarks 
  #       shell: bash
  #       working-directory: ${{ env.mounted_directory_name }}/duckdb-old-${{ matrix.versions.old_name }}
  #       run: |
  #         # we do this so new added benchmarks that break duckdb old
  #         # do not cause failures.
  #         rm -rf ../duckdb-curr-${{ matrix.versions.new_name }}/benchmark
  #         mkdir ../duckdb-curr-${{ matrix.versions.new_name }}/benchmark
  #         cp -r benchmark ../duckdb-curr-${{ matrix.versions.new_name }}
  #         ls -lah ../duckdb-curr-${{ matrix.versions.new_name }}

  #     - name: Link duckdb-curr/duckdb_benchmark_data to tpch_sf100.duckdb and tpcds_sf100.duckdb
  #       shell: bash 
  #       working-directory: ${{ env.mounted_directory_name }}/duckdb-curr-${{ matrix.versions.new_name }}
  #       run: |
  #         # make sure there is no duckdb_benchmark_data left over from the previous run
  #         rm -rf duckdb_benchmark_data
  #         mkdir duckdb_benchmark_data
  #         cd duckdb_benchmark_data
  #         ln -s ${{ github.workspace }}/${{ env.mounted_directory_name }}/tpch_sf100.duckdb .
  #         ln -s ${{ github.workspace }}/${{ env.mounted_directory_name }}/tpcds_sf100.duckdb .
    
  #     - name: Link duckdb-old/duckdb_benchmark_data to tpch_sf100.duckdb and tpcds_sf100.duckdb
  #       shell: bash 
  #       working-directory: ${{ env.mounted_directory_name }}/duckdb-old-${{ matrix.versions.old_name }}
  #       run: |
  #         # make sure there is no duckdb_benchmark_data left over from the previous run
  #         rm -rf duckdb_benchmark_data
  #         mkdir duckdb_benchmark_data
  #         cd duckdb_benchmark_data
  #         ln -s ${{ github.workspace }}/${{ env.mounted_directory_name }}/tpch_sf100.duckdb .
  #         ln -s ${{ github.workspace }}/${{ env.mounted_directory_name }}/tpcds_sf100.duckdb .
    
  # run-regression-tests:
  #   name: TEST - ${{ matrix.versions.new_name }} vs ${{ matrix.versions.old_name }}
  #   if: always()
  #   needs: 
  #     - define-matrix
  #     - configure-mount-and-download-benchmark-data
  #     - build-and-setup
  #   runs-on: self-hosted
  #   strategy:
  #     fail-fast: false
  #     matrix:
  #       versions: ${{ fromJSON(needs.define-matrix.outputs.versions) }}
  #   steps:          
  #     - name: Run Regression Test ${{ matrix.versions.new_name }} vs ${{ matrix.versions.old_name }}
  #       continue-on-error: true
  #       shell: bash
  #       working-directory: ${{ env.mounted_directory_name }}
  #       run: |
  #         export disable_timeout=""
  #         tests=('large/tpch.csv' 'large/tpcds.csv' 'micro_extended.csv')
          
  #         for test in ${tests[@]}; do
  #           if [[ "${test}" == "large/tpcds.csv" ]]; then
  #               disable_timeout="--disable-timeout"
  #           fi  
            
  #           test_type=$(echo "${test}" | sed -e 's/\//_/g'  -e 's/\.csv//' )
  #           file_name="regression_output_${test_type}_${{ matrix.versions.new_name }}_${{ matrix.versions.old_name }}.txt"

  #           python duckdb-curr-${{ matrix.versions.new_name }}/scripts/regression/test_runner.py \
  #             --old=duckdb-old-${{ matrix.versions.old_name }}/build/release/benchmark/benchmark_runner \
  #             --new=duckdb-curr-${{ matrix.versions.new_name }}/build/release/benchmark/benchmark_runner \
  #             --benchmarks=duckdb-curr-${{ matrix.versions.new_name }}/.github/regression/$test $disable_timeout \
  #             --regression-threshold-seconds=${{ env.REGESSION_THRESHOLD_SECONDS }} --verbose > "${file_name}"
  #         done
          
  #     - name: Upload results
  #       uses: actions/upload-artifact@v4
  #       if: success()
  #       with:
  #         name: ${{ matrix.versions.new_name }}_${{ matrix.versions.old_name }}
  #         path: ${{ env.mounted_directory_name }}/regression_*_${{ matrix.versions.new_name }}_${{ matrix.versions.old_name }}.txt
  #         if-no-files-found: error
  
  # file-issue:
  #   name: File Issue
  #   if: always()
  #   # if: ${{ contains(github.ref_name, 'main') }}
  #   needs: 
  #     - define-matrix
  #     - start-runner
  #     - configure-mount-and-download-benchmark-data
  #     - build-and-setup
  #     - run-regression-tests
  #   runs-on: self-hosted

  #   steps:
  #     - name: Sparse-checkout repo with a script
  #       uses: actions/checkout@v4
  #       with:
  #         sparse-checkout: scripts/engineering/weekly_regression/collect_issues.py
  #         path: ${{ env.mounted_directory_name }}/also_scripts

  #     - name: Collect issues on Benchmarks
  #       shell: bash
  #       working-directory: ${{ env.mounted_directory_name }}
  #       run: |
  #         cp ../duckdb_previous_version_pairs.json versions.json
  #         python also_scripts/scripts/engineering/weekly_regression/collect_issues.py versions.json

  #     - name: File issue on preparation steps
  #       shell: bash
  #       working-directory: ${{ env.mounted_directory_name }}
  #       if: |
  #           contains(github.ref_name, 'main') && 
  #           (needs.configure-mount-and-download-benchmark-data.result != 'success' ||
  #           needs.build-and-setup.result != 'success')
  #       run: |
  #         echo -e "Benchmark preparation steps have failed, please check the \
  #           [workflow run](https://github.com/duckdblabs/duckdb-internal/actions/runs/${{ github.run_id }}) for details.\n\n" > report.txt

  #     - name: Create Regressions Report
  #       shell: bash
  #       working-directory: ${{ env.mounted_directory_name }}
  #       run: |
  #         if [ -f  issue_body.txt ]; then
  #           echo "Regressions detected, GitHub issue will be filed."
  #           echo "# Regression tests" >> report.txt
  #           cat issue_body.txt >> report.txt
  #           echo "Latest WeeklyRegression run: [Run Link](https://github.com/duckdblabs/duckdb-internal/actions/runs/${{ github.run_id }})" >> report.txt
  #         fi

  #     - name: Create Issue
  #       shell: bash
  #       working-directory: ${{ env.mounted_directory_name }}
  #       run: |
  #         if [ -f report.txt ]; then
  #           # create issue
  #           gh issue create --repo ${{ env.gh_issue_repo }} --title "Weekly Regression Test Failure" --body-file report.txt
  #           cat report.txt
  #         fi
      
  #     - name: Upload report file
  #       uses: actions/upload-artifact@v4
  #       if: success()
  #       with:
  #         name: REPORT
  #         path: ${{ env.mounted_directory_name }}/report.txt
  #         if-no-files-found: error

  # shutdown:
  #   name: shut down
  #   if: always()
  #   runs-on: self-hosted
  #   needs:
  #     - start-runner
  #     - file-issue

  #   steps:
  #     - name: shutdown
  #       shell: bash
  #       run: sudo shutdown
